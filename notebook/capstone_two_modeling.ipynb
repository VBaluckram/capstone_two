{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Forecasting City Finances - Modeling</center>\n",
    "\n",
    "\n",
    "## Import Packages\n",
    "The needed packages for treating the data are imported below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "We now load the data that we cleaned in the data wrangling step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state_city</th>\n",
       "      <th>rev_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1977</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>5342.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1978</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>5948.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>6158.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>5654.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981</td>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>6192.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year     state_city  rev_total\n",
       "0  1977  AK: Anchorage    5342.24\n",
       "1  1978  AK: Anchorage    5948.99\n",
       "2  1979  AK: Anchorage    6158.68\n",
       "3  1980  AK: Anchorage    5654.93\n",
       "4  1981  AK: Anchorage    6192.83"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd_data = '/Users/Varishth/Desktop/Springboard_Projects/capstone_two/data/timeseries_data.csv'\n",
    "df_TS = pd.read_csv(pwd_data)\n",
    "df_TS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slight field adjusments\n",
    "We have two slight adjusments to make: 1) make the year the index of the dataframe, and 2) pivot the dataframe to ensure that the index of the dataframe is only the unique datetime values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_city</th>\n",
       "      <th>rev_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1977-01-01</th>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>5342.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978-01-01</th>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>5948.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-01-01</th>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>6158.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>5654.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-01</th>\n",
       "      <td>AK: Anchorage</td>\n",
       "      <td>6192.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               state_city  rev_total\n",
       "year                                \n",
       "1977-01-01  AK: Anchorage    5342.24\n",
       "1978-01-01  AK: Anchorage    5948.99\n",
       "1979-01-01  AK: Anchorage    6158.68\n",
       "1980-01-01  AK: Anchorage    5654.93\n",
       "1981-01-01  AK: Anchorage    6192.83"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the year column as the index\n",
    "df_TS.index = pd.to_datetime(df_TS.year, format='%Y')\n",
    "df_TS.drop(\"year\",axis=1, inplace=True)\n",
    "\n",
    "df_TS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>state_city</th>\n",
       "      <th>AK: Anchorage</th>\n",
       "      <th>AK: Fairbanks</th>\n",
       "      <th>AL: Birmingham</th>\n",
       "      <th>AL: Gadsden</th>\n",
       "      <th>AL: Mobile</th>\n",
       "      <th>AL: Montgomery</th>\n",
       "      <th>AR: Ft. Smith</th>\n",
       "      <th>AR: Little Rock</th>\n",
       "      <th>AR: Pine Bluff</th>\n",
       "      <th>AZ: Mesa</th>\n",
       "      <th>...</th>\n",
       "      <th>WA: Seattle</th>\n",
       "      <th>WA: Spokane</th>\n",
       "      <th>WA: Tacoma</th>\n",
       "      <th>WI: Madison</th>\n",
       "      <th>WI: Milwaukee</th>\n",
       "      <th>WV: Charleston</th>\n",
       "      <th>WV: Huntington</th>\n",
       "      <th>WV: Wheeling</th>\n",
       "      <th>WY: Casper</th>\n",
       "      <th>WY: Cheyenne</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1977-01-01</th>\n",
       "      <td>5342.24</td>\n",
       "      <td>10694.10</td>\n",
       "      <td>3585.56</td>\n",
       "      <td>2110.24</td>\n",
       "      <td>2422.69</td>\n",
       "      <td>2404.86</td>\n",
       "      <td>1974.81</td>\n",
       "      <td>2595.48</td>\n",
       "      <td>1843.03</td>\n",
       "      <td>4141.52</td>\n",
       "      <td>...</td>\n",
       "      <td>5087.61</td>\n",
       "      <td>3340.49</td>\n",
       "      <td>5764.70</td>\n",
       "      <td>3694.34</td>\n",
       "      <td>4962.91</td>\n",
       "      <td>3267.59</td>\n",
       "      <td>2719.36</td>\n",
       "      <td>2615.27</td>\n",
       "      <td>3565.21</td>\n",
       "      <td>3371.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978-01-01</th>\n",
       "      <td>5948.99</td>\n",
       "      <td>9879.05</td>\n",
       "      <td>3812.13</td>\n",
       "      <td>2421.50</td>\n",
       "      <td>2409.94</td>\n",
       "      <td>2414.52</td>\n",
       "      <td>2102.94</td>\n",
       "      <td>2603.06</td>\n",
       "      <td>1838.35</td>\n",
       "      <td>4486.91</td>\n",
       "      <td>...</td>\n",
       "      <td>5296.63</td>\n",
       "      <td>3019.63</td>\n",
       "      <td>6132.73</td>\n",
       "      <td>3628.95</td>\n",
       "      <td>5291.06</td>\n",
       "      <td>2997.67</td>\n",
       "      <td>2589.10</td>\n",
       "      <td>2710.00</td>\n",
       "      <td>3874.99</td>\n",
       "      <td>3655.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-01-01</th>\n",
       "      <td>6158.68</td>\n",
       "      <td>9956.39</td>\n",
       "      <td>3683.44</td>\n",
       "      <td>2495.91</td>\n",
       "      <td>2518.27</td>\n",
       "      <td>2339.53</td>\n",
       "      <td>2014.04</td>\n",
       "      <td>2569.56</td>\n",
       "      <td>1815.43</td>\n",
       "      <td>4393.78</td>\n",
       "      <td>...</td>\n",
       "      <td>5200.40</td>\n",
       "      <td>3063.28</td>\n",
       "      <td>6082.74</td>\n",
       "      <td>3415.57</td>\n",
       "      <td>5194.10</td>\n",
       "      <td>3371.48</td>\n",
       "      <td>2435.91</td>\n",
       "      <td>2545.52</td>\n",
       "      <td>3827.20</td>\n",
       "      <td>3834.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>5654.93</td>\n",
       "      <td>9228.33</td>\n",
       "      <td>3413.75</td>\n",
       "      <td>2319.35</td>\n",
       "      <td>2332.95</td>\n",
       "      <td>2208.98</td>\n",
       "      <td>1907.19</td>\n",
       "      <td>2339.04</td>\n",
       "      <td>1807.27</td>\n",
       "      <td>4353.79</td>\n",
       "      <td>...</td>\n",
       "      <td>4873.79</td>\n",
       "      <td>3016.78</td>\n",
       "      <td>5530.47</td>\n",
       "      <td>3268.03</td>\n",
       "      <td>4859.10</td>\n",
       "      <td>2880.31</td>\n",
       "      <td>2574.81</td>\n",
       "      <td>2391.60</td>\n",
       "      <td>4053.25</td>\n",
       "      <td>3653.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-01</th>\n",
       "      <td>6192.83</td>\n",
       "      <td>9846.12</td>\n",
       "      <td>3354.20</td>\n",
       "      <td>2498.66</td>\n",
       "      <td>2400.45</td>\n",
       "      <td>2120.81</td>\n",
       "      <td>1994.07</td>\n",
       "      <td>2571.07</td>\n",
       "      <td>2172.49</td>\n",
       "      <td>4267.93</td>\n",
       "      <td>...</td>\n",
       "      <td>4848.54</td>\n",
       "      <td>2942.93</td>\n",
       "      <td>5493.17</td>\n",
       "      <td>3414.55</td>\n",
       "      <td>4657.09</td>\n",
       "      <td>3090.90</td>\n",
       "      <td>2868.05</td>\n",
       "      <td>2848.57</td>\n",
       "      <td>4698.07</td>\n",
       "      <td>3790.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "state_city  AK: Anchorage  AK: Fairbanks  AL: Birmingham  AL: Gadsden  \\\n",
       "year                                                                    \n",
       "1977-01-01        5342.24       10694.10         3585.56      2110.24   \n",
       "1978-01-01        5948.99        9879.05         3812.13      2421.50   \n",
       "1979-01-01        6158.68        9956.39         3683.44      2495.91   \n",
       "1980-01-01        5654.93        9228.33         3413.75      2319.35   \n",
       "1981-01-01        6192.83        9846.12         3354.20      2498.66   \n",
       "\n",
       "state_city  AL: Mobile  AL: Montgomery  AR: Ft. Smith  AR: Little Rock  \\\n",
       "year                                                                     \n",
       "1977-01-01     2422.69         2404.86        1974.81          2595.48   \n",
       "1978-01-01     2409.94         2414.52        2102.94          2603.06   \n",
       "1979-01-01     2518.27         2339.53        2014.04          2569.56   \n",
       "1980-01-01     2332.95         2208.98        1907.19          2339.04   \n",
       "1981-01-01     2400.45         2120.81        1994.07          2571.07   \n",
       "\n",
       "state_city  AR: Pine Bluff  AZ: Mesa  ...  WA: Seattle  WA: Spokane  \\\n",
       "year                                  ...                             \n",
       "1977-01-01         1843.03   4141.52  ...      5087.61      3340.49   \n",
       "1978-01-01         1838.35   4486.91  ...      5296.63      3019.63   \n",
       "1979-01-01         1815.43   4393.78  ...      5200.40      3063.28   \n",
       "1980-01-01         1807.27   4353.79  ...      4873.79      3016.78   \n",
       "1981-01-01         2172.49   4267.93  ...      4848.54      2942.93   \n",
       "\n",
       "state_city  WA: Tacoma  WI: Madison  WI: Milwaukee  WV: Charleston  \\\n",
       "year                                                                 \n",
       "1977-01-01     5764.70      3694.34        4962.91         3267.59   \n",
       "1978-01-01     6132.73      3628.95        5291.06         2997.67   \n",
       "1979-01-01     6082.74      3415.57        5194.10         3371.48   \n",
       "1980-01-01     5530.47      3268.03        4859.10         2880.31   \n",
       "1981-01-01     5493.17      3414.55        4657.09         3090.90   \n",
       "\n",
       "state_city  WV: Huntington  WV: Wheeling  WY: Casper  WY: Cheyenne  \n",
       "year                                                                \n",
       "1977-01-01         2719.36       2615.27     3565.21       3371.69  \n",
       "1978-01-01         2589.10       2710.00     3874.99       3655.38  \n",
       "1979-01-01         2435.91       2545.52     3827.20       3834.86  \n",
       "1980-01-01         2574.81       2391.60     4053.25       3653.97  \n",
       "1981-01-01         2868.05       2848.57     4698.07       3790.32  \n",
       "\n",
       "[5 rows x 212 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_TS_pivot = df_TS.pivot(columns='state_city', values='rev_total')\n",
    "df_TS_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1977-01-01', '1978-01-01', '1979-01-01', '1980-01-01',\n",
       "               '1981-01-01', '1982-01-01', '1983-01-01', '1984-01-01',\n",
       "               '1985-01-01', '1986-01-01', '1987-01-01', '1988-01-01',\n",
       "               '1989-01-01', '1990-01-01', '1991-01-01', '1992-01-01',\n",
       "               '1993-01-01', '1994-01-01', '1995-01-01', '1996-01-01',\n",
       "               '1997-01-01', '1998-01-01', '1999-01-01', '2000-01-01',\n",
       "               '2001-01-01', '2002-01-01', '2003-01-01', '2004-01-01',\n",
       "               '2005-01-01', '2006-01-01', '2007-01-01', '2008-01-01',\n",
       "               '2009-01-01', '2010-01-01', '2011-01-01', '2012-01-01',\n",
       "               '2013-01-01', '2014-01-01', '2015-01-01', '2016-01-01',\n",
       "               '2017-01-01'],\n",
       "              dtype='datetime64[ns]', freq='AS-JAN')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_TS_pivot.index = pd.DatetimeIndex(df_TS_pivot.index.values,freq=df_TS_pivot.index.inferred_freq)\n",
    "df_TS_pivot.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create useful functions!\n",
    "In order to facilitate/automate the training process, we create functions that we can later call in iterative loops.\n",
    "Four specific functions are created below: 1) `check_adfuller`, 2) `check_mean_std`, 3) `evaluate_arima_model` and 4) `evaluate_models`.\n",
    "\n",
    "The first two models can be used if we need to test for stationarity. The third is designed to train a specific ARIMA model and return the mean squared error of the test and the fourth model is designed to iterate through a set of ARIMA models to return the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_adfuller\n",
    "def check_adfuller(ts):\n",
    "    # Dickey-Fuller test\n",
    "    result = adfuller(ts, autolag='AIC')\n",
    "    print('Test statistic: ' , result[0])\n",
    "    print('p-value: '  ,result[1])\n",
    "    print('Critical Values:' ,result[4])\n",
    "    \n",
    "# check_mean_std\n",
    "def check_mean_std(ts):\n",
    "    #Rolling statistics\n",
    "    rolmean = ts.rolling(3).mean()\n",
    "    rolstd = ts.rolling(3).std()\n",
    "    plt.figure(figsize=(22,10))   \n",
    "    orig = plt.plot(ts, color='red',label='Original')\n",
    "    mean = plt.plot(rolmean, color='black', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='green', label = 'Rolling Std')\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Mean Temperature\")\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details about the evaluation of each ARIMA model\n",
    "The following function is meant to test each ARIMA model. To do so, the dataset is first made stationary using the log-difference method. To evaluate the performance of each ARIMA model, the dataset is split into a training section and a testing section (85%-15% split). Since this is a timeseries, a marching approach is adopted. Explicitly, a marching approach means that the model will use the first 85% of the dataset, to forecast the next data point, then add this forecast to the training set, and repeat the process until a forecast is generate for each data point in the testing set.\n",
    "\n",
    "Before checking how the model performed, the forecasted data is first transformed back to a non-stationary form. The performance of the ARIMA model is evaluated using two metrics: 1) the mean squared error and 2) the absolute percent error, between the forecasted values and the testing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function called evaluate_arima_model to find the MSE of a single ARIMA model \n",
    "def evaluate_arima_model(data, arima_order):\n",
    "    # Make data stationary\n",
    "    data_stationary = (np.log(data)).diff().dropna()\n",
    "    \n",
    "    split=int(len(data_stationary) * 0.85) \n",
    "    # Make train and test variables, with 'train, test'\n",
    "    train, test = data_stationary[0:split], data_stationary[split:len(data_stationary)]\n",
    "    past=[x for x in train]\n",
    "    # make predictions\n",
    "    predictions = list()\n",
    "    for i in range(len(test)):#timestep-wise comparison between test data and one-step prediction ARIMA model. \n",
    "        model = ARIMA(past, order=arima_order)\n",
    "        model_fit = model.fit(disp=0)\n",
    "        future = model_fit.forecast()[0]\n",
    "        predictions.append(future)\n",
    "        past.append(test[i])\n",
    "    # calculate out of sample error\n",
    "    error = mean_squared_error(test, predictions)\n",
    "    \n",
    "    # convert forecasted time series back to stationay form\n",
    "    last = data[0:-len(test)][-1]\n",
    "    predictions_unstationary=[None] * len(test)\n",
    "    for i in range(len(test)):\n",
    "        predictions_unstationary[i]= np.exp(predictions[i])*last\n",
    "        last = predictions_unstationary[i]\n",
    "\n",
    "    abs_pct_err = \"{:.2%}\".format ( (np.abs(data[-len(test):].values -  \n",
    "                                        np.transpose(predictions_unstationary)) \n",
    "                                    / data[-len(test):].values ).mean())\n",
    "    # Return the error\n",
    "    return error, abs_pct_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details choosing the best ARIMA model\n",
    "The following function takes several different p, d, and q values to form different ARIMA models. The function iteratively evaluates each of these models, and then compares their performance. Finally the function returns the best function as well as the absolute % error metric calculated during the evaluation phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function called evaluate_models to evaluate different ARIMA models with several different p, d, and q values.\n",
    "def evaluate_models(dataset, p_values, q_values):\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    # Iterate through p_values\n",
    "    for p in p_values:\n",
    "        # Iterate through d_values\n",
    "         for d in d_values:\n",
    "             # Iterate through q_values\n",
    "            for q in q_values:\n",
    "                # p, d, q iterator variables in that order\n",
    "                order = (p,d,q)\n",
    "                try:\n",
    "                    # Make a variable called mse for the Mean squared error\n",
    "                    mse, abs_pct_err = evaluate_arima_model(dataset, order)\n",
    "                    if mse < best_score:\n",
    "                        best_score, best_cfg = mse, order\n",
    "                    #print('ARIMA%s MSE=%.3f' % (order,mse))\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    #print('Best ARIMA%s MSE=%.3f' % (best_cfg, best_score)) \n",
    "    return best_cfg, abs_pct_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, testing and picking the best ARIMA model\n",
    "In order to generate different ARIMA models, a set of p, d and q values is first created. These are fed as input in the above ARIMA evaluation functions and for each city, the p-d-q combination that leads to the lowest mean squared error is picked. Therefore, each city will have an optimized ARIMA model based on its historical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we choose a couple of values to try for each parameter: p_values, d_values and q_values\n",
    "# Fill in the blanks as appropriate\n",
    "p_values = [x for x in range(0, 3)]\n",
    "d_values = [x for x in range(0, 3)]\n",
    "q_values = [x for x in range(0, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_orders = pd.DataFrame(index=df_TS_pivot.columns, columns=['best_ARIMA_order', 'Training Error(%)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best ARIMA models for each city...\n",
      "0% done\n",
      "7% done\n",
      "14% done\n",
      "21% done\n",
      "28% done\n",
      "35% done\n",
      "42% done\n",
      "50% done\n",
      "57% done\n",
      "64% done\n",
      "71% done\n",
      "78% done\n",
      "85% done\n",
      "92% done\n",
      "99% done\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"Finding best ARIMA models for each city...\")\n",
    "for state_city in df_TS_pivot.columns:\n",
    "    if list(df_TS_pivot.columns).index(state_city) % 15 == 0:\n",
    "        print(\"{:.0%}\".format(list(df_TS_pivot.columns).index(state_city) / len(df_TS_pivot.columns))+\" done\")\n",
    "    dataset = df_TS_pivot[state_city]\n",
    "    best_cfg, abs_pct_err = evaluate_models(dataset, p_values, q_values)\n",
    "    df_model_orders.at[state_city, 'best_ARIMA_order'] =  best_cfg\n",
    "    df_model_orders.at[state_city, 'Training Error(%)'] = abs_pct_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best ARIMA model found for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_ARIMA_order</th>\n",
       "      <th>Training Error(%)</th>\n",
       "      <th>train_err_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AK: Anchorage</th>\n",
       "      <td>(2, 1, 2)</td>\n",
       "      <td>30.58%</td>\n",
       "      <td>0.3058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK: Fairbanks</th>\n",
       "      <td>(0, 1, 2)</td>\n",
       "      <td>24.60%</td>\n",
       "      <td>0.2460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL: Birmingham</th>\n",
       "      <td>(2, 1, 1)</td>\n",
       "      <td>9.87%</td>\n",
       "      <td>0.0987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL: Gadsden</th>\n",
       "      <td>(1, 1, 1)</td>\n",
       "      <td>1.90%</td>\n",
       "      <td>0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL: Mobile</th>\n",
       "      <td>(0, 1, 0)</td>\n",
       "      <td>8.75%</td>\n",
       "      <td>0.0875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               best_ARIMA_order Training Error(%)  train_err_num\n",
       "state_city                                                      \n",
       "AK: Anchorage         (2, 1, 2)            30.58%         0.3058\n",
       "AK: Fairbanks         (0, 1, 2)            24.60%         0.2460\n",
       "AL: Birmingham        (2, 1, 1)             9.87%         0.0987\n",
       "AL: Gadsden           (1, 1, 1)             1.90%         0.0190\n",
       "AL: Mobile            (0, 1, 0)             8.75%         0.0875"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_orders.to_csv(r'/Users/Varishth/Desktop/Springboard_Projects/capstone_two/data/best_ARIMA_citywise.csv',index=False)\n",
    "df_model_orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting out-of-sample data and displaying the data\n",
    "The following function serves two purposes:\n",
    "* Firstly, it takes as input a city and uses the chosen ARIMA model for that city to predict and out-of-sample revenue for the city\n",
    "* Secondly, the function also encodes visualization which will be later called in a widget to showcase the performance of the chosen ARIMA model for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_city_revenue(chosen_state_city=\"IL: Chicago\"):\n",
    "    # fit model\n",
    "    state_city = chosen_state_city\n",
    "    actual_ts = (np.log(df_TS_pivot[state_city])).diff().dropna()\n",
    "    arima_order = df_model_orders.loc[state_city].best_ARIMA_order\n",
    "    split=int(len(actual_ts) * 0.85)\n",
    "\n",
    "    # Make train and test variables, with 'train, test'\n",
    "    train, test = actual_ts[0:split], actual_ts[split:len(actual_ts)]\n",
    "    past=[x for x in train]\n",
    "    # make predictions\n",
    "    predictions = list()\n",
    "    ci_lo = list()\n",
    "    ci_hi = list()\n",
    "    for i in range(len(test)):#timestep-wise comparison between test data and one-step prediction ARIMA model. \n",
    "        model = ARIMA(past, order=arima_order)\n",
    "        model_fit = model.fit(disp=0)\n",
    "        future = model_fit.forecast()[0]\n",
    "        ci = model_fit.forecast()[2][0]\n",
    "        predictions.append(future)\n",
    "        ci_lo.append(ci[0])\n",
    "        ci_hi.append(ci[1])\n",
    "        past.append(test[i])\n",
    "\n",
    "    # Out of sample forecast\n",
    "    model = ARIMA(actual_ts, order=arima_order)\n",
    "    model_fit = model.fit()\n",
    "    forecast_ts = model_fit.forecast(alpha=0.05)\n",
    "\n",
    "    # convert forecasted time series back to unstationary form\n",
    "    last = df_TS_pivot[state_city][-1]\n",
    "    forecast_ts_unstationary=[None] * 2\n",
    "    forecast_ts_unstationary[0] = last\n",
    "    forecast_ts_unstationary[1] = last * np.exp(forecast_ts[0])\n",
    "\n",
    "    # convert to unstationary form\n",
    "    last = df_TS_pivot[state_city][0:-len(test)][-1]\n",
    "    predictions_unstationary=[None] * len(predictions)\n",
    "    ci_lo_unstationary=[None] * len(ci_lo)\n",
    "    ci_hi_unstationary=[None] * len(ci_hi)\n",
    "    for i in range(len(predictions)):\n",
    "        predictions_unstationary[i]= np.exp(predictions[i][0])*last\n",
    "        ci_lo_unstationary[i] = np.exp(ci_lo[i])*last\n",
    "        ci_hi_unstationary[i] = np.exp(ci_hi[i])*last\n",
    "        last = predictions_unstationary[i]\n",
    "        \n",
    "    # pull in absolute error\n",
    "    abs_pct_err = \"{:.2%}\".format ( (np.abs(df_TS_pivot[state_city][-len(test):].values -  \n",
    "                                        np.transpose(predictions_unstationary)) \n",
    "                                    / df_TS_pivot[state_city][-len(test):].values ).mean())\n",
    "\n",
    "    # visualization\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(df_TS_pivot[state_city], 'k',label = \"Original\")\n",
    "    plt.plot(test.index, predictions_unstationary, 'k--',label='Step-wise Testing')\n",
    "    plt.fill_between(test.index, ci_lo_unstationary, ci_hi_unstationary, \n",
    "                     color='k', alpha=.05,label='Step-wise Testing Error Bounds')\n",
    "    plt.figtext(0.3, 0.59, \"Absolute % error in testing = \"+abs_pct_err, wrap=True, \n",
    "                horizontalalignment='center', fontsize=12)\n",
    "    plt.plot(pd.to_datetime(['2017-01-01', '2018-01-01']), forecast_ts_unstationary, 'r--', label = \"Forecast\")\n",
    "    plt.title(\"{} - Yearly Total Revenue\".format(state_city), fontsize=14)\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Total Revenue\")\n",
    "    plt.legend(loc='upper left', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The worst performance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_ARIMA_order</th>\n",
       "      <th>Training Error(%)</th>\n",
       "      <th>train_err_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PA: Harrisburg</th>\n",
       "      <td>(2, 0, 0)</td>\n",
       "      <td>923.82%</td>\n",
       "      <td>9.2382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MO: St. Louis</th>\n",
       "      <td>(0, 1, 2)</td>\n",
       "      <td>184.24%</td>\n",
       "      <td>1.8424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA: San Diego</th>\n",
       "      <td>(0, 1, 2)</td>\n",
       "      <td>182.84%</td>\n",
       "      <td>1.8284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO: Denver</th>\n",
       "      <td>(2, 1, 2)</td>\n",
       "      <td>135.42%</td>\n",
       "      <td>1.3542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA: Boston</th>\n",
       "      <td>(0, 0, 0)</td>\n",
       "      <td>125.77%</td>\n",
       "      <td>1.2577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               best_ARIMA_order Training Error(%)  train_err_num\n",
       "state_city                                                      \n",
       "PA: Harrisburg        (2, 0, 0)           923.82%         9.2382\n",
       "MO: St. Louis         (0, 1, 2)           184.24%         1.8424\n",
       "CA: San Diego         (0, 1, 2)           182.84%         1.8284\n",
       "CO: Denver            (2, 1, 2)           135.42%         1.3542\n",
       "MA: Boston            (0, 0, 0)           125.77%         1.2577"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_orders['train_err_num'] = df_model_orders['Training Error(%)'].str.rstrip('%').astype(float) / 100\n",
    "df_model_orders.sort_values(by=['train_err_num'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best performance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_ARIMA_order</th>\n",
       "      <th>Training Error(%)</th>\n",
       "      <th>train_err_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL: Gadsden</th>\n",
       "      <td>(1, 1, 1)</td>\n",
       "      <td>1.90%</td>\n",
       "      <td>0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR: Little Rock</th>\n",
       "      <td>(0, 2, 2)</td>\n",
       "      <td>2.22%</td>\n",
       "      <td>0.0222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC: Charleston</th>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>2.55%</td>\n",
       "      <td>0.0255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX: El Paso</th>\n",
       "      <td>(2, 1, 0)</td>\n",
       "      <td>2.64%</td>\n",
       "      <td>0.0264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MS: Jackson</th>\n",
       "      <td>(2, 0, 2)</td>\n",
       "      <td>2.90%</td>\n",
       "      <td>0.0290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                best_ARIMA_order Training Error(%)  train_err_num\n",
       "state_city                                                       \n",
       "AL: Gadsden            (1, 1, 1)             1.90%         0.0190\n",
       "AR: Little Rock        (0, 2, 2)             2.22%         0.0222\n",
       "SC: Charleston         (0, 0, 1)             2.55%         0.0255\n",
       "TX: El Paso            (2, 1, 0)             2.64%         0.0264\n",
       "MS: Jackson            (2, 0, 2)             2.90%         0.0290"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_orders.sort_values(by=['train_err_num']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization widget\n",
    "Below is a widget which allows you to toggle between cities, and easily visualize the training performance of the chosen ARIMA model, as well as, the out-of-sample prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08621dccc49340f7b790f941737739c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='chosen_state_city', index=53, options=('AK: Anchorage', 'AK: Fairb…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.interact(predict_city_revenue, chosen_state_city=df_TS_pivot.columns);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
